{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dec845",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Grzegorz Statkiewicz, Mateusz Matukiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644fa77",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The structure of the direcotry should be as follows:\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── train.pkl\n",
    "│   └── test_no_target.pkl\n",
    "└── main.ipynb\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e644",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92cc3a2",
   "metadata": {},
   "source": [
    "Select the device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8098fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f8042",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b2553",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd66a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab81607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2939 training samples.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bdf9f",
   "metadata": {},
   "source": [
    "Print sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f678d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: (array([145., 145.,  80.,  92.,   5.,  65.,  15.,  32.,  33.,  78.,  78.,\n",
      "        78.,  12., 145., 145.,  92.,  64.,  17.,  12.,  69.,  69.,  47.,\n",
      "        93.,  78.,  12.,  12.,  88.,  78., 190.,  71.,  12.,  47., 156.,\n",
      "        12.,  92.,  47.,  78.,  64.,  64.,  92., 149.,  39., 124., 126.,\n",
      "        71., 156.,  78.,  78.,  12.,   5.,  80.,  30.,  78., 119., 140.,\n",
      "        45.,  88.,  78.,  78.,  78.,  12.,  47.,  13., 124.,  79.,  77.,\n",
      "        78.,  47.,  30.,  78.,  71.,  76.,  92.,  92.,  13., 159.,  76.,\n",
      "       124.,  76., 159., 190.,  76.,  65.,  65.,  88.,  88., 159.,   8.,\n",
      "         8., 159.,   5., 124.,  13., 124., 124., 125.,  44., 126.,  13.,\n",
      "        93., 119.,  36.,  47.,  12.,  47.,  13.,  28.,  13.,  13.,  14.,\n",
      "       127.,  13.,   7.,   7.,  92.,  13., 172., 127.,  12., 156.,  44.,\n",
      "        47.,  85.,  13.,  13.,   7.,  47., 125.,  37., 127., 127., 127.,\n",
      "        44.,  33.,  33.,  45.,  39.,  39., 124., 124., 159.,  12.,  92.,\n",
      "        30., 141.,  92., 152.,  78.,  92.,  65.,  15.,  60.,  88.,  78.,\n",
      "       156.,  77., 156., 151., 151.,  44., 124.,  13., 124., 119., 119.,\n",
      "        45.,  92.,  13.,  92.,  88.,  47.,  92.,   0.,  13.,  47.,  12.,\n",
      "        93.,  12.,  47.,  13.,  93.,  46.,  12.,  46.,  46., 124., 124.,\n",
      "        60., 124.,  12., 125., 157.,  44., 126.,  13.,  93., 119.,  78.,\n",
      "        12.,  13.,  90.,  78.,  30.,  76.,  12., 159.,   5.,  30.,  78.,\n",
      "       119., 140.,  45.,  88.,  78.,  78.,  78.,  12., 145.,  80.,  92.,\n",
      "         5.,  65.,  15.,  32.,  33.,  78.,  78.,  78.,  13., 145.,  -1.,\n",
      "        -1.,  -1.,  -1.]), 0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "idx = random.randint(0, len(train_data) - 1)\n",
    "print(f\"Sample data: {train_data[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51ae7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in train_data]\n",
    "labels = [label for (seq, label) in train_data]\n",
    "\n",
    "# Find the max chord index (vocab size, since chords are ints)\n",
    "all_chords = set()\n",
    "for seq in sequences:\n",
    "    all_chords.update(seq.tolist())\n",
    "vocab_size = int(max(all_chords)) + 2  # +1 for max, +1 for padding idx=0\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131fa0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    padded_seqs = pad_sequence(seqs, batch_first=True, padding_value=0)\n",
    "    return padded_seqs, lengths, torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98a55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, h_n = self.rnn(packed)\n",
    "        # Use last hidden state (h_n) for classification\n",
    "        logits = self.fc(h_n[-1])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "057000a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_split, val_data_split = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in train_data_split]\n",
    "train_labels = [label for (seq, label) in train_data_split]\n",
    "val_sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in val_data_split]\n",
    "val_labels = [label for (seq, label) in val_data_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fc0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChordDataset(train_sequences, train_labels)\n",
    "val_dataset = ChordDataset(val_sequences, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4625a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_seqs, batch_lengths, batch_labels in val_loader:\n",
    "            batch_seqs = batch_seqs.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            logits = model(batch_seqs, batch_lengths)\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            total_correct += (preds == batch_labels).sum().item()\n",
    "            total_samples += batch_labels.size(0)\n",
    "            total_loss += loss.item() * batch_seqs.size(0)\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 64\n",
    "OUTPUT_DIM = 5\n",
    "\n",
    "model = SimpleRNNClassifier(vocab_size, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ca7223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 74/74 [02:42<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.0928 | Train Acc: 0.9783 | Val Loss: 0.3496 | Val Acc: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 74/74 [02:43<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 0.0868 | Train Acc: 0.9787 | Val Loss: 0.3467 | Val Acc: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 74/74 [02:43<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.0837 | Train Acc: 0.9792 | Val Loss: 0.3454 | Val Acc: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 74/74 [02:41<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.0811 | Train Acc: 0.9817 | Val Loss: 0.3546 | Val Acc: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 74/74 [02:43<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.0779 | Train Acc: 0.9817 | Val Loss: 0.3526 | Val Acc: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 74/74 [02:40<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.0757 | Train Acc: 0.9817 | Val Loss: 0.3607 | Val Acc: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 74/74 [02:43<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.0732 | Train Acc: 0.9830 | Val Loss: 0.3574 | Val Acc: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 74/74 [02:41<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 0.0717 | Train Acc: 0.9843 | Val Loss: 0.3606 | Val Acc: 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 74/74 [02:46<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 0.0685 | Train Acc: 0.9847 | Val Loss: 0.3701 | Val Acc: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 74/74 [02:45<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 0.0674 | Train Acc: 0.9855 | Val Loss: 0.3664 | Val Acc: 0.9048\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch_seqs, batch_lengths, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        batch_seqs = batch_seqs.to(device)\n",
    "        batch_lengths = batch_lengths.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_seqs, batch_lengths)\n",
    "        loss = criterion(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_seqs.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        total_correct += (preds == batch_labels).sum().item()\n",
    "        total_samples += batch_labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    train_acc = total_correct / total_samples\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
