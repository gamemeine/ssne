{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dec845",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Grzegorz Statkiewicz, Mateusz Matukiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644fa77",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The structure of the direcotry should be as follows:\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── train.pkl\n",
    "│   └── test_no_target.pkl\n",
    "└── main.ipynb\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e644",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92cc3a2",
   "metadata": {},
   "source": [
    "Select the device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8098fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746dc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff3e06",
   "metadata": {},
   "source": [
    "### Config for reproductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f8042",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b2553",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd66a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab81607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads data from a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a560b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2939 training samples.\n"
     ]
    }
   ],
   "source": [
    "train_raw_data = load_data(train_path)\n",
    "\n",
    "print(f\"Loaded {len(train_raw_data)} training samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a373d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test data later\n",
    "# test_raw_data = load_data(test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bdf9f",
   "metadata": {},
   "source": [
    "Print sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f678d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: (array([ 80.,  80.,  80., 158.,  92.,  92.,  93.,  12.,  12.,  12.,   0.,\n",
      "         0.,  92.,  92.,  13.,  93., 119.,  12.,  13., 172.,  77.,  92.,\n",
      "         0.,   0.,  92.,  80.,  80., 158.,  92.,  92.,  93.,  12.,  12.,\n",
      "        12.,   0.,   0.,  92.,  92.,  13.,  93., 119.,  12.,  13., 172.,\n",
      "        77.,  92.,   0.,   0.,   0.,  12., 112.,  12.,   7.,  92., 127.,\n",
      "        60., 157., 172.,  80.,  80.,  80.,  92.,  92., 127.,  74.,   7.,\n",
      "       172.,  80.,  92.,  92.,  80.,  80.]), 0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "idx = random.randint(0, len(train_raw_data) - 1)\n",
    "print(f\"Sample data: {train_raw_data[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fda28b",
   "metadata": {},
   "source": [
    "### chords and composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ac69d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (chords): 184\n",
      "PAD_IDX: 0, UNK_IDX: 1\n",
      "Number of composers (classes): 5\n"
     ]
    }
   ],
   "source": [
    "all_chords_train = Counter()\n",
    "all_composers_train = Counter()\n",
    "\n",
    "for sequence, composer in train_raw_data:\n",
    "    all_chords_train.update(sequence)\n",
    "    all_composers_train.update([composer])\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "\n",
    "# Rezerwujemy indeks 0 dla PAD_TOKEN i 1 dla UNK_TOKEN\n",
    "chord_to_idx = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "current_idx = 2 # Zaczynamy indeksowanie rzeczywistych akordów od 2\n",
    "for chord, _ in all_chords_train.most_common():\n",
    "    if chord not in chord_to_idx: # Upewnij się, że nie nadpisujemy specjalnych tokenów\n",
    "        chord_to_idx[chord] = current_idx\n",
    "        current_idx += 1\n",
    "\n",
    "idx_to_chord = {idx: chord for chord, idx in chord_to_idx.items()}\n",
    "\n",
    "\n",
    "VOCAB_SIZE = len(chord_to_idx)\n",
    "PAD_IDX = chord_to_idx[PAD_TOKEN] # = 0\n",
    "UNK_IDX = chord_to_idx[UNK_TOKEN] # = 1\n",
    "\n",
    "print(f\"Vocabulary size (chords): {VOCAB_SIZE}\")\n",
    "print(f\"PAD_IDX: {PAD_IDX}, UNK_IDX: {UNK_IDX}\")\n",
    "\n",
    "composer_to_idx = {composer: i for i, (composer, _) in enumerate(all_composers_train.most_common())}\n",
    "idx_to_composer = {idx: composer for composer, idx in composer_to_idx.items()}\n",
    "OUTPUT_DIM = len(composer_to_idx)\n",
    "\n",
    "print(f\"Number of composers (classes): {OUTPUT_DIM}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
