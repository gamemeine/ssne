{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02dec845",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Grzegorz Statkiewicz, Mateusz Matukiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644fa77",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The structure of the direcotry should be as follows:\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── train.pkl\n",
    "│   └── test_no_target.pkl\n",
    "└── main.ipynb\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290e644",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92cc3a2",
   "metadata": {},
   "source": [
    "Select the device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26c9c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 25 13:14:57 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     On  |   00000000:1C:00.0  On |                  N/A |\n",
      "|  0%   48C    P8             18W /  130W |     875MiB /   6144MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       377      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8098fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746dc9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff3e06",
   "metadata": {},
   "source": [
    "### Config for reproductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f8042",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b2553",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd66a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab81607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads data from a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a560b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2939 training samples.\n",
      "(array([ -1.,  -1.,  -1., ...,  78.,  40., 144.], shape=(4756,)), 0)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data(train_path)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training samples.\")\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a373d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compositors = {0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}\n",
    "num_classes = len(compositors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d8c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in train_data]\n",
    "labels = [label for (seq, label) in train_data]\n",
    "\n",
    "# Find the max chord index (vocab size, since chords are ints)\n",
    "all_chords = set()\n",
    "for seq in sequences:\n",
    "    all_chords.update(seq.tolist())\n",
    "vocab_size = int(max(all_chords)) + 2  # +1 for max, +1 for padding idx=0\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408de834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = [seq + 1 for seq in sequences]\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    padded_seqs = pad_sequence(seqs, batch_first=True, padding_value=0)\n",
    "    return padded_seqs, lengths, torch.tensor(labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61595462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data_split, val_data_split = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in train_data_split]\n",
    "train_labels = [label for (seq, label) in train_data_split]\n",
    "val_sequences = [torch.tensor(seq, dtype=torch.long) for (seq, label) in val_data_split]\n",
    "val_labels = [label for (seq, label) in val_data_split]\n",
    "\n",
    "train_dataset = ChordDataset(train_sequences, train_labels)\n",
    "val_dataset = ChordDataset(val_sequences, val_labels)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e772fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "class_sample_counts = np.array([train_labels.count(i) for i in range(num_classes)])\n",
    "weights = 1. / class_sample_counts\n",
    "\n",
    "sample_weights = np.array([weights[label] for label in train_labels])\n",
    "sample_weights = torch.DoubleTensor(sample_weights)\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "sampled_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c4f44",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0031c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, num_layers, dropout_p=0.5, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0) # padding_idx=0 assumes 0 is used for padding\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  \n",
    "            dropout=dropout_p if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        fc_input_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        self.fc = nn.Linear(fc_input_dim, output_dim)\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # LSTM\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed_embedded)\n",
    "\n",
    "    \n",
    "        if self.bidirectional:\n",
    "            h_n_last_layer_forward = h_n[-2, :, :]\n",
    "            h_n_last_layer_backward = h_n[-1, :, :]\n",
    "            hidden = torch.cat((h_n_last_layer_forward, h_n_last_layer_backward), dim=1)\n",
    "        else:\n",
    "            hidden = h_n[-1, :, :]\n",
    "\n",
    "\n",
    "        hidden = self.dropout(hidden)\n",
    "        logits = self.fc(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05700535",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = vocab_size\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 64\n",
    "OUTPUT_DIM = 5\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT_P = 0.4\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d5b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        num_layers=2,\n",
    "        dropout_p=DROPOUT_P,\n",
    "        bidirectional=False\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e893b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm\n",
    "counts = torch.tensor([1630, 478, 154, 441, 236], dtype=torch.float) # from data-exploration\n",
    "class_weights = 1.0 / counts\n",
    "class_weights = class_weights / class_weights.sum() * len(counts)  # Normalize to num_classes\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248571d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(193, 32, padding_idx=0)\n",
      "  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, dropout=0.4)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "Number of parameters: 64869\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe50858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  50%|█████     | 5/10 [00:16<00:14,  2.97s/it]"
     ]
    }
   ],
   "source": [
    "from training import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    early_stopping=True,\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, val_loader, epochs=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
