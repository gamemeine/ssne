{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e390bac3",
   "metadata": {},
   "source": [
    "# Generative models\n",
    "\n",
    "Grzegorz Statkiewicz, Mateusz Matukiewicz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb6a0e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "306d6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5278c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 12 23:35:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     On  |   00000000:1C:00.0  On |                  N/A |\n",
      "|  0%   47C    P8             17W /  130W |    5660MiB /   6144MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3265      C   /python3.10                                 N/A      |\n",
      "|    0   N/A  N/A     10491      C   /python3.10                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bef940",
   "metadata": {},
   "source": [
    "Select the device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f657f1",
   "metadata": {},
   "source": [
    "## Prepare the dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# train_mean = [0.3186241388320923, 0.2931755483150482, 0.3017965853214264]\n",
    "# train_std = [0.2762017846107483, 0.2654302418231964, 0.2686000168323517]\n",
    "\n",
    "train_mean = [0.5, 0.5, 0.5]\n",
    "train_std = [0.5, 0.5, 0.5]\n",
    "\n",
    "\n",
    "class ContrastStretch(object):\n",
    "    def __call__(self, img):\n",
    "        # img: Tensor [C,H,W] in [0,1]\n",
    "        lo, hi = img.min(), img.max()\n",
    "        return (img - lo) / (hi - lo + 1e-5)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ContrastStretch(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = \"./data/train\"\n",
    "train_ds = ImageFolder(train_dir, transform=transform)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "\n",
    "print(f\"Number of train images: {len(train_ds)}\")\n",
    "print(f\"Number of train classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9402ebd1",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24a1fc",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn import VariationalAutoencoder as VAE\n",
    "from gnn import VAETrainer\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "IMG_CHANNELS = 3\n",
    "latent_dim = 100\n",
    "\n",
    "# model\n",
    "vae_model = VAE(IMG_CHANNELS, latent_dim=latent_dim).to(device)\n",
    "\n",
    "# optimizers\n",
    "vae_optimizer = torch.optim.Adam(vae_model.parameters(), lr=0.0001)\n",
    "vae_scheduler = optim.lr_scheduler.ExponentialLR(optimizer=vae_optimizer, gamma=0.99)\n",
    "\n",
    "# trainer\n",
    "vae_trainer = VAETrainer(\n",
    "    vae_model=vae_model,\n",
    "    optimizer=vae_optimizer,\n",
    "    scheduler=vae_scheduler,\n",
    "    latent_dim=latent_dim,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6f793",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfadeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_trainer.fit(train_dl, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "results_id = time.time()\n",
    "results_dir = f\"./vae_results/{results_id}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "mean_t = torch.tensor(train_mean).view(1, 3, 1, 1).to(device)\n",
    "std_t = torch.tensor(train_std).view(1, 3, 1, 1).to(device)\n",
    "\n",
    "vae_model.eval()\n",
    "\n",
    "num_samples = len(test_ds)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        sample, label = test_ds[i]\n",
    "\n",
    "\n",
    "        z = torch.randn(1, latent_dim, device=device)\n",
    "        img = vae_model.decode(z)\n",
    "\n",
    "        img = img * std_t + mean_t\n",
    "\n",
    "        fname = os.path.join(results_dir, f\"class_{label}_sample_{i}.jpg\")\n",
    "        save_image(img.clamp(0, 1), fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711c9b4",
   "metadata": {},
   "source": [
    "Calculate the FID between test set and generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "\n",
    "test_flat_dir = \"./data/test_flat\"\n",
    "generated_dir = results_dir\n",
    "\n",
    "fid = calculate_fid_given_paths([test_flat_dir, generated_dir], batch_size, device, dims=2048, num_workers=1)\n",
    "\n",
    "print(f\"FID: {fid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
